from guesslet.prompts.cqa_prompt import PromptDict
from transformers import PreTrainedTokenizer


def tokenize(sample: PromptDict, tokenizer: PreTrainedTokenizer, max_length=None):
    """Tokenizes the `prompt` field of a data sample.

    This function tokenizes the `prompt` field from a given data sample using a specified tokenizer.
    It optionally truncates the input to a maximum length. The function returns a dictionary
    containing `input_ids` and `attention_mask` generated by the tokenizer.

    Args:
        sample (dict): A dictionary representing a data sample. This dictionary must have
                       a key named "prompt" which contains the text to be tokenized.
        tokenizer (AutoTokenizer): An instance of `AutoTokenizer` from the Hugging Face Transformers
                                   library, pre-initialized and ready to use for tokenization.
        max_length (int, optional): The maximum length of the tokenized output. If the text
                                    exceeds this length, it will be truncated to fit.
                                    Defaults to None, in which case no truncation is performed.

    Returns:
        dict: A dictionary with two keys, `input_ids` and `attention_mask`, containing the
              tokenized output from the tokenizer. The exact structure of this dictionary
              (including any additional keys) might depend on the specific tokenizer used.

    Note:
        The `return_length` argument in the tokenizer call is set based on the presence of
        `max_length`. If `max_length` is not None, `truncation` is set to True, and
        `max_length` is enforced. Otherwise, tokenization proceeds without truncation, and
        `return_length` is set to False, which is not a valid tokenizer argument and might
        need correction based on the intended functionality.
    """
    if max_length:
        return tokenizer(sample["prompt"], truncation=True, max_length=max_length)
    # Corrected the return statement to exclude `return_length` which is not a valid argument
    return tokenizer(sample["prompt"])